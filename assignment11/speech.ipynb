{"nbformat": 4, "nbformat_minor": 2, "metadata": {"language_info": {"pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["import string\n", "import os\n", "import speech_recognition as sr\n", "import distance\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["class Speech:\n", "    def __init__(self):\n", "        self.original = []\n", "        self.recognized = []\n", "        self.distances = []\n", "    def read_original(self, inFile):\n", "        f = open(inFile, 'r')\n", "        idx = 0\n", "        self.original.append([])\n", "        punct = string.punctuation\n", "        punct += '\u2019'\n", "        for line in f:\n", "            for c in punct:\n", "                line = line.replace(c, '')\n", "            for word in line.split():\n", "                self.original[idx].append(word.lower())\n", "            self.original.append([])\n", "            idx += 1"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["    def conv_audio(self, inDir):\n", "        audio_files_to_text = ['' for _ in range(25)]\n", "        r = sr.Recognizer()\n", "        # convert to string\n", "        for file in os.listdir(inDir):\n", "            tens_digit = 0\n", "            idx = file.find('.')\n", "            file_base = file[:idx]\n", "            if file_base[-2].isnumeric():\n", "                tens_digit = (ord(file_base[-2]) - 48) * 10\n", "            ones_digit = ord(file_base[-1]) - 48\n", "            file_joined = os.path.join(inDir, file)\n", "            message = \"\"\n", "            with sr.WavFile(file_joined) as source:\n", "                audio = r.record(source)\n", "                message = r.recognize_sphinx(audio)\n", "            position = (tens_digit + ones_digit) - 1\n", "            audio_files_to_text[position] = message\n", "        # parse\n", "        for idx,  line in enumerate(audio_files_to_text):\n", "            punct = string.punctuation\n", "            punct += '\u2019'\n", "            self.recognized.append([])\n", "            for c in punct:\n", "                line = line.replace(c, '')\n", "            for word in line.split():\n", "                self.recognized[idx].append(word.lower())\n", "    def comp_string(self):\n", "        for s1, s2 in zip(self.original, self.recognized):\n", "            score = distance.levenshtein(s1, s2) / max(len(s1), len(s2))\n", "            self.distances.append(score)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["def read_in_all_audio_submissions(inFile, inDir):\n", "    result = [[] for _ in range(25)]\n", "    for the_dir in os.listdir(inDir):\n", "        sp = Speech()\n", "        sp.read_original(inFile)\n", "        sp.conv_audio(os.path.join(inDir, the_dir))\n", "        sp.comp_string()\n", "        for idx, value in enumerate(sp.distances):\n", "            result[idx].append(value)\n", "    return result"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["if __name__ == '__main__':\n", "    fig, ax = plt.subplots(figsize=(20,10))\n", "    x = ['Sent{i}'.format(i = i + 1) for i in range(25)]\n", "    results = read_in_all_audio_submissions(\"How Speech Recognition Works.txt\", \"audio_files\")\n", "    sns.boxplot(x, results, ax = ax)\n", "    plt.show()"]}]}